{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last step\n",
    "# Predict segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import utils.metrics\n",
    "import utils.model_builder\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurable parameter:\n",
    "* config (experiment)\n",
    "* GPU\n",
    "* input folder \n",
    "* output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NO = \"2\"\n",
    "input_directory =  \"/storage/data/2018_tim_tracking/2018_06_29_lineage_tracking_blainey/images/movies/12_2018_MCF10_Drug_full/images\"\n",
    "output_directory = \"/storage/data/2018_tim_tracking/2018_06_29_lineage_tracking_blainey/images/movies/201902/predictions_08\"\n",
    "experiment_name = \"08\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config_vars\n",
    "\n",
    "# load configuration file\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "# output directory\n",
    "config_vars[\"probmap_out_dir\"] = output_directory\n",
    "\n",
    "# initialize GPU\n",
    "configuration = tf.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = GPU_NO\n",
    "\n",
    "session = tf.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_images_from_directory(input_directory):\n",
    "    image_names = glob.glob(input_directory + \"/*png\")\n",
    "    images = []\n",
    "    imagebuffer = skimage.io.imread_collection( image_names )\n",
    "    for image in imagebuffer:\n",
    "        #image = skimage.io.imread(filename)\n",
    "        images.append(skimage.color.rgb2gray(image))\n",
    "\n",
    "    #print(\"found {} images\".format(len(imagebuffer)))\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    dim1 = np.floor(images.shape[1]/16) * 16 \n",
    "    dim1 = dim1.astype(np.int)\n",
    "    dim2 = np.floor(images.shape[2]/16) * 16 \n",
    "    dim2 = dim2.astype(np.int)\n",
    "\n",
    "    images = images[:,0:dim1,0:dim2]\n",
    "\n",
    "    dim1 = images.shape[1]\n",
    "    dim2 = images.shape[2]\n",
    "\n",
    "    images = images.reshape((-1, dim1, dim2, 1))\n",
    "\n",
    "    #print(dim1,dim2)\n",
    "\n",
    "    # preprocess images\n",
    "    percentile = 99.9\n",
    "    for image_no in range(images.shape[0]):\n",
    "        orig_img = images[image_no,:,:,:]\n",
    "\n",
    "        high = np.percentile(orig_img, percentile)\n",
    "        low = np.percentile(orig_img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, orig_img)\n",
    "        img = np.maximum(low, img)\n",
    "        img = (img - low) / (high - low) \n",
    "        img = skimage.img_as_ubyte(img) \n",
    "        images[image_no,:,:,:] = img # gives float64, thus cast to 8 bit later\n",
    "\n",
    "\n",
    "\n",
    "    images = images.astype(float)\n",
    "    images = images / 256\n",
    "\n",
    "    return(images,imagebuffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for directory in tqdm.tqdm(os.listdir(input_directory)):\n",
    "    \n",
    "    if os.path.exists(os.path.join(output_directory,directory)):\n",
    "        print(\"Folder {} processed!\".format(directory))\n",
    "    else:\n",
    "        \n",
    "    \n",
    "        [images,imagebuffer] = load_and_prepare_images_from_directory(os.path.join(input_directory,directory))\n",
    "\n",
    "        # build model and load weights\n",
    "        dim1 = images.shape[1]\n",
    "        dim2 = images.shape[2]\n",
    "        \n",
    "        \n",
    "        model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "        model.load_weights(config_vars[\"model_file\"])\n",
    "\n",
    "        #  prediction \n",
    "        predictions = model.predict(images, batch_size=1)\n",
    "\n",
    "\n",
    "        os.makedirs(os.path.join(output_directory,directory)) \n",
    "        for i in range(len(images)):\n",
    "\n",
    "            image_savename = os.path.join(\n",
    "                output_directory, \n",
    "                directory, \n",
    "                os.path.basename(imagebuffer.files[i])\n",
    "            )\n",
    "\n",
    "            probmap = predictions[i].squeeze()\n",
    "\n",
    "            skimage.io.imsave(os.path.splitext(image_savename)[0] + \".png\", probmap)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model and loading weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(x)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:17: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  a = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(a)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:20: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  a = keras.layers.BatchNormalization(**option_dict_bn)(a)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:26: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  b = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(b)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:29: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  b = keras.layers.BatchNormalization(**option_dict_bn)(b)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:35: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  c = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(c)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:38: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  c = keras.layers.BatchNormalization(**option_dict_bn)(c)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:44: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  d = keras.layers.Convolution2D(512, 3, 3, **option_dict_conv)(d)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:47: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  d = keras.layers.BatchNormalization(**option_dict_bn)(d)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:58: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  e = keras.layers.Convolution2D(256, 3, 3, **option_dict_conv)(e)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:61: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  e = keras.layers.BatchNormalization(**option_dict_bn)(e)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:70: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  f = keras.layers.Convolution2D(128, 3, 3, **option_dict_conv)(f)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:73: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  f = keras.layers.BatchNormalization(**option_dict_bn)(f)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:82: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  y = keras.layers.Convolution2D(64, 3, 3, **option_dict_conv)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:85: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9)`\n",
      "  y = keras.layers.BatchNormalization(**option_dict_bn)(y)\n",
      "/home/cells2numbers/unet4neutrophils/utils/model_builder.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (1, 1), activation=\"relu\", padding=\"same\")`\n",
      "  y = keras.layers.Convolution2D(3, 1, 1, **option_dict_conv)(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 145/145 [02:45<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 145/145 [02:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 145/145 [02:32<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 145/145 [02:42<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 145/145 [02:36<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images in folder  6wells_wash_001.nd2 - 6wells_wash_001.nd2 (series 03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/0x00b1/com/github/scikit-image/scikit-image/skimage/util/dtype.py:123: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      " 33%|███▎      | 48/145 [00:51<01:43,  1.06s/it]"
     ]
    }
   ],
   "source": [
    "print(\"building model and loading weights\")\n",
    "dim1 = 1024\n",
    "dim2 = 2048\n",
    "model = utils.model_builder.get_model_3_class(dim1, dim2)\n",
    "model.load_weights(config_vars[\"model_file\"])\n",
    "\n",
    "for directory in os.listdir(input_directory):\n",
    "    \n",
    "    #if os.path.exists(os.path.join(output_directory,directory)):\n",
    "    #    print(\"Folder {} processed!\".format(directory))\n",
    "    #else:\n",
    "        \n",
    "        print(\"loading images in folder  {}\".format(directory))\n",
    "        [images,imagebuffer] = load_and_prepare_images_from_directory(os.path.join(input_directory,directory))\n",
    "\n",
    "        if os.path.exists(os.path.join(output_directory,directory)):\n",
    "            print(\"Folder exists, overwriting predictions\".format(directory))\n",
    "        else:\n",
    "            os.makedirs(os.path.join(output_directory,directory))\n",
    "            \n",
    "        for i in tqdm.tqdm(range(images.shape[0])):\n",
    "            image = images[i,0:1024,:,:]\n",
    "            image = image.reshape(-1, image.shape[0],image.shape[1],1)\n",
    "            prediction = model.predict(image, batch_size=1)\n",
    "            \n",
    "            probmap = prediction.squeeze()\n",
    "                \n",
    "            image_savename = os.path.join(\n",
    "                output_directory, \n",
    "                directory, \n",
    "                os.path.basename(imagebuffer.files[i])\n",
    "            )\n",
    "            with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    skimage.io.imsave(os.path.splitext(image_savename)[0] + \".png\", probmap)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
